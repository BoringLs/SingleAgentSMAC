# SingleAgentSMAC
A single agent PPO implied in SMAC, just for study
map: 8m

# Need following SC2 packages
[SMAC](https://github.com/oxwhirl/smac?tab=readme-ov-file)ï¼Œ[SMAC-HARD](https://github.com/devindeng94/smac-hard) 

# Start
just run run.py
```
python -u run.py
```
